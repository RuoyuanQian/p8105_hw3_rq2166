---
title: "p8105_hw3_rq2166"
author: "Ruoyuan Qian"
date: "10/8/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(rnoaa)
library(ggridges)
library(p8105.datasets) 
#install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010")
data("accel_data")
data("instacart")

#install.packages("kableExtra")
library(kableExtra)
library(ggridges)
devtools::install_github("thomasp85/patchwork")
library(patchwork)
```
# Problem 1

## a)
**Description of `instacart`**

`The number of aisle and the most items ordered from the aisles: `

There are ``r instacart %>% group_by(aisle) %>% summarize(n = n()) %>% pull(n) %>% length()``aisles in it, and the most items are order from ``r instacart %>% group_by(aisle) %>% summarize(n = n()) %>% filter(n == max(n)) %>% pull(aisle)``aisles in total.

The number of observation in `instacart` is ``r instacart%>%pull(aisle)%>%length()``. And there are ``r instacart%>%length()`` variables in it. Each row in the dataset is a product from an order. There is a single order per user in this dataset. There are ``r instacart %>% distinct(user_id) %>% pull(user_id) %>% length()`` unique users in it and there are ``r instacart %>% distinct(department) %>% pull(department) %>% length()`` unique departments in it.

The key variables in `instacart` include information on order, including the order sequence number(`order_number`) and the time of the order(`order_dow`, `order_hour_of_day`), product(`product_name`), aisle(`aisle`) and department(`department`).



## b)

Make a plot shows the number of items ordered in each aisle.
```{r}  
instacart %>% 
  group_by(aisle) %>% 
  summarize(n = n()) %>% 
  filter(n > 10000) %>% 
ggplot(aes(x= aisle)) + 
  geom_bar(aes(weight=n)) +
  coord_flip()+
labs(
       x    = "Aisle",
       y    = "The number of items ordered in each aisle",
       title = "Plot 1 The number of items ordered in each aisle "
       )
  
```

There are ``r instacart %>% group_by(aisle) %>% summarize(n = n()) %>% filter(n > 10000) %>% pull(aisle) %>% length()`` aisles with the number of items ordered larger than 10000, ``r instacart %>% group_by(aisle) %>%summarize(n = n()) %>% filter(n == max(n)) %>% pull(aisle) `` , ``r instacart %>% group_by(aisle) %>%summarize(n = n()) %>%  mutate(rank=rank(-n)) %>% filter(rank == 2) %>% pull(aisle) `` and ``r instacart %>% group_by(aisle) %>%summarize(n = n()) %>%  mutate(rank=rank(-n)) %>% filter(rank == 3) %>% pull(aisle) `` are the three most popular aisles over all. The average number of items ordered in aisles is about``r round((instacart %>% group_by(aisle) %>%summarize(n = n()) %>% filter(n >= 10000)  %>% pull(n) %>% mean))``.

## c)

Make a table showing the three most popular items in “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
```{r}

instacart %>% 
  group_by(aisle,product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care",
                      "packaged vegetables fruits")
          ) %>% 
  summarize( "number_of_times" = n()) %>% 
  mutate(rank=rank(-number_of_times)) %>% 
  filter(rank %in% c(1,2,3)) %>% 
  ungroup(aisle,product_name) %>% 
  select(-aisle,-rank) %>% 
  pivot_wider(
    names_from  = product_name, 
    values_from = number_of_times
  ) %>% 
  knitr::kable(caption = "Table 1  The three most popular items in baking ingredients, dog food care, and packaged vegetables fruits",format = "html") 
#add_header_abov(c("baking ingredients" = 3,"dog food care" = 3, "packaged vegetables fruits" = 3))

```


```{r}
Three_most_popular = 
instacart %>% 
  group_by(aisle,product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care",
                      "packaged vegetables fruits")
          ) %>% 
  summarize( "number_of_times" = n()) %>% 
  mutate(rank=rank(-number_of_times)) %>% 
  filter(rank %in% c(1,2,3)) %>% 
  arrange(aisle,rank) 

Three_most_popular %>% 
  knitr::kable(caption = "Table 1  The three most popular items in baking ingredients, dog food care, and packaged vegetables fruits",format = "html") 

```
According to the Table 1, we can see the numbers of items ordered from `packaged vegetables fruits` are much larger than others, the most popular item in it is ``r Three_most_popular %>% filter(aisle == "packaged vegetables fruits" & rank==1) %>% pull(aisle)`` and its number of ordered times is ``r Three_most_popular %>% filter(aisle == "packaged vegetables fruits" & rank==1) %>% pull(number_of_times)``. 
The numbers of items ordered from `dog food care` are the least one, the most popular item in it is ``r Three_most_popular %>% filter(aisle == "dog food care" & rank==1) %>% pull(aisle)`` and its number of ordered times is ``r Three_most_popular %>% filter(aisle == "dog food care" & rank==1) %>% pull(number_of_times)``.

```{r}
mean_hour = 
instacart %>% 
  group_by(product_name,order_dow) %>% 
  filter(product_name %in% c("Pink Lady Apples",
                             "Coffee Ice Cream")) %>%
  select(order_dow,order_hour_of_day,product_name)%>% 
  arrange(order_dow) %>% 
  mutate( mean = mean(order_hour_of_day),
          week = recode(order_dow, 
       "0"="Sunday",
       "1"="Monday",
       "2"="Tuesday",
       "3"="Wednesday",
       "4"="Thursday",
       "5"="Friday",
       "6"="Saturday")) %>% 
  ungroup(product_name,order_dow) %>%
  select(-order_hour_of_day,-order_dow) %>% 
      distinct() %>% 
  pivot_wider(
    names_from  = week, 
    values_from = mean
  ) 
mean_hour %>% 
  knitr::kable(caption = "Table 2  The mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered",
               format = "html")
 
  
  
```
According to the Table 2, the hours of purchasing `Pink Lady Apples` on each day of the week is earlier than `Coffee Ice Cream`. 
The latest ordered hour for `Pink Lady Apples` appears in `Wednesday`, and the earliest ordered hour appears in `Monday`.
The latest ordered hour for `Coffee Ice Cream` appears in `Tuesday`, and the earliest ordered hour appears in `Friday`.

# Problem 2

## Data cleaning
```{r}
brfss = 
brfss_smart2010 %>% 
     janitor::clean_names()%>%
  filter(topic == "Overall Health"&
         response %in%
           c("Excellent","Very good",
             "Good","Fair","Poor")) %>% 
  mutate(response=factor(response, ordered=T,
          level=c("Poor","Fair","Good","Very good","Excellent"
             ))) 
```
## a)

``r brfss%>% filter(year==2002) %>% group_by(locationabbr) %>% summarize(n = n()) %>%filter(n  >= 7) %>% pull(locationabbr) %>% length()`` states( ``r brfss%>% filter(year==2002) %>% group_by(locationabbr) %>% summarize(n = n()) %>%filter(n  >= 7) %>% pull(locationabbr)``) were observed at 7 or more locations in 2002, and ``r brfss%>% filter(year==2010) %>% group_by(locationabbr) %>% summarize(n = n()) %>%filter(n  >= 7) %>% pull(locationabbr) %>% length()`` states (``r brfss%>% filter(year==2010) %>% group_by(locationabbr) %>% summarize(n = n()) %>%filter(n  >= 7) %>% pull(locationabbr)``) were observed at 7 or more locations in 2010.

## b)

Limited the data to `"Excellent" response`
```{r}
data_value_mean = brfss %>% 
  group_by(locationabbr,year) %>% 
  filter(response=="Excellent") %>% 
  mutate(mean = mean(data_value,na.rm=TRUE)) %>% 
  select(year,locationabbr,mean) %>% 
  distinct()
```

Make `“spaghetti”` plot of average value over time within a state
```{r }
data_value_mean %>% 
  ggplot(aes(x=year, y=mean,color=locationabbr,group=locationabbr))+
  geom_line()+
labs(
       x    = "Year",
       y    = "Average",
       title = "Plot 2  Spaghetti plot of avrage value over time within a state "
       )

```

According to the Plot2, there is a extreme decreasing trend for most of the states in `2005`, especially for the ``r data_value_mean %>% ungroup(locationabbr,year) %>% filter(mean == min(mean) , year==2005) %>% pull(locationabbr)`` state. Among all states, ``r data_value_mean %>%ungroup(locationabbr,year) %>%group_by(locationabbr) %>% mutate(a=mean(mean)) %>% select(-year,-mean) %>% distinct()%>%ungroup(locationabbr) %>%  filter(a==max(a)) %>% pull(locationabbr)`` state contained the highest mean value over the years while ``r data_value_mean %>%ungroup(locationabbr,year) %>%group_by(locationabbr) %>% mutate(a=mean(mean)) %>% select(-year,-mean) %>% distinct()%>%ungroup(locationabbr) %>%  filter(a==min(a)) %>% pull(locationabbr)`` state contained the lowest mean value over the years.

## c)

Distribution of `data_value` for responses among locations in NY State.
```{r}
df =  brfss %>% 
  filter( locationabbr=="NY") %>% 
  select(year,locationdesc,data_value,response)

```

```{r}
plot_2006_3 =
  df %>% 
    filter(year == 2006) %>% 
  group_by(response) %>% 
  mutate(mean_NY = mean(data_value,na.rm=TRUE)) %>% 
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .4)+
  xlim(-1,46) +
  viridis::scale_color_viridis(
    discrete = TRUE
  )+
labs(
       x    = "data_value",
       title = "Plot 3  Distribution of NY State in 2006"
       )

plot_2010_3 =
  df %>% 
    filter(year == 2010) %>% 
  group_by(response) %>% 
  mutate(mean_NY = mean(data_value,na.rm=TRUE)) %>% 
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .4)+
  xlim(-1,46) +
  viridis::scale_color_viridis(
    discrete = TRUE
  )+
labs(
       x    = "data_value",
       title = "Plot 4  Distribution of NY State in 2010"
       )

plot_2006_3/plot_2010_3


```
According to the Plot 3,


According to Plot 3 and 4, the distributions of `Poor` and `Excellent` in 2006 were similar to the associated response in 2010, respectively. And they almost remained in the same position among 2006 and 2010. 
However, `Fair` became more dispersed compared to 2006, `Good` and `Very good` were in opposite positions in the 2006 and 2010 distributions, `Good` was less dispersed compared to 2006.
Moreover, there was a trend in 2010 by number from big to small: `Very good`, `Good`, `Excellent`, `Fair` and then `Poor`.


# Problem 3

## a)

Tidy data
```{r}
 accel_data = read_csv( "./data/accel_data.csv")%>%
  janitor::clean_names()%>%
  drop_na()%>%
  mutate(
    day = factor(day,ordered=T,
                  level=c("Monday", "Tuesday",
                          "Wednesday", 
                          "Thursday", "Friday", 
                          "Saturday", "Sunday")),
     weekday_weekend =  case_when(
      as.numeric(day) < 6 ~ "Weekday",
      as.numeric(day) >= 6 ~ "Weekend",
      TRUE ~ ""
    )
  ) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    names_prefix = "activity_" ) %>% 
  arrange(week,day_id)
```
**Description**

`accel_data`

The number of observation in `accel_data` is ``r accel_data%>%pull(week)%>%length()``. And there are ``r accel_data%>%length()`` variables in it.

The variables in `accel_data` include information of time, including the variables of week(`week`, `day_id`, `day`, `weekday_weekend`) and information of activity(`activity`, `value`).

## b)

Table of total activity over the day
```{r}
total_activity = 
 accel_data %>% 
  group_by(week,day_id) %>% 
  mutate(
    total = sum(value)
  ) %>% 
  select(week,day,total) %>% 
  distinct() 

total_activity %>% 
  knitr::kable(caption = "Table 3  Total activity for each day",format = "html")

```

Plot of total activity over the day
```{r}
  
total_activity %>%
  ungroup(week) %>% 
  ggplot(aes(x=day_id,y=total,color=week))+
  geom_line()+
labs(
       x    = "day",
       y    = "total activity each day",
       title = "Plot 5 Total activity over the day "
       )

```

It is hard to say the trend from the long table, so I drew an associated plot with `day` for `x axis` and `total activity` for `y axis`. There is a increasing trend among the `first` and `second` week and than a decreasing trend in `third` week. Besides, there are two equal minimums, which are ``r total_activity %>% ungroup(week,day_id) %>% filter(total == min(total)) %>% distinct(total) %>% pull(total)``, on the ``r total_activity %>% ungroup(week,day_id) %>% filter(total == min(total)) %>% pull(day)``,week ``r total_activity %>% ungroup(week,day_id) %>% filter(total == min(total)) %>% pull(week)``, respectively, and the maxium is  ``r total_activity %>% ungroup(week,day_id) %>% filter(total == max(total)) %>% pull(total)``, it is on the ``r total_activity %>% ungroup(week,day_id) %>% filter(total == max(total)) %>% pull(day)``, week ``r total_activity %>% ungroup(week,day_id) %>% filter(total == max(total)) %>% pull(week)``.

```{r}
 accel_data %>% 
  mutate(day_id=as.character(day_id)) %>% 
  ggplot(aes(x= activity,y=value,
             color=day,group=day_id))+
  geom_line(alpha = .7)+
  viridis::scale_color_viridis(
    discrete = TRUE
  )+
labs(
       x    = "Activity across 24 hours",
       y    = "Value",
       title = "Plot 6  24-hour activity time courses for each day "
       )

```

According to the Plot 6, there is an sharply drop among `“activity counts” ` in the morning in all days, and there are about three peaks in the plot, the first one appeared early in the morning contributed by Thursdays and Fridays, the second one appeared at noon, contributed by Thursdays and Sundays and the third peak appeared at the nightfall, contributed by Sundays. 
Moreover, the `“activity counts” `on Mondays were flater than others. And the `“activity counts” `on Thursday and Sundays were more fluctuating than others.